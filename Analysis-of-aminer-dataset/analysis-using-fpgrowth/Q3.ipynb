{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3'\n",
    "from pyspark import SparkContext\n",
    "from pyspark.mllib.fpm import FPGrowth\n",
    "import math\n",
    "\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '5g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filePath = \"publications.txt\"\n",
    "# filePath = \"sample-data.txt\"\n",
    "file = open(filePath,'r')\n",
    "\n",
    "authorVenues = {}   #{Author, list(Venues)}\n",
    "\n",
    "for line in file:      \n",
    "         \n",
    "    # get list for authors for each publication    \n",
    "    if line.startswith(\"#@\"):\n",
    "        line = line[2:].strip()\n",
    "        if line != \"\":\n",
    "            validAuthors = line.split(\",\")\n",
    "\n",
    "    # construct list of venues for each author\n",
    "    if line.startswith(\"#c\"):\n",
    "        venue = line[2:].strip()\n",
    "        if venue != \"\":        \n",
    "            for author in validAuthors:\n",
    "                if authorVenues.get(author) is None:\n",
    "                    authorVenues[author] = [venue]\n",
    "                else:\n",
    "                    authorVenues[author] = authorVenues.get(author) + [venue]\n",
    "                authorVenues[author] = list(set(authorVenues.get(author)))                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "venues = sc.parallelize(list(authorVenues.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992\n"
     ]
    }
   ],
   "source": [
    "support = 0.001\n",
    "model = FPGrowth.train(venues, minSupport=support, numPartitions=1)\n",
    "result = model.freqItemsets().collect()\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "support = 0.0004 # or 0.00001\n",
    "model = FPGrowth.train(venues, minSupport=support, numPartitions=1)\n",
    "result = model.freqItemsets().collect()\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>On my system, when support is decreased to 0.4e-3 an 1e-4, FP-growth doesn't train the models, even when 5g of memory is assigned to Spark! It might be because, the size of FP-Tree grows exponentially along with the count of possible frequent itemsets. Thereby, consuming all the heap memory!<br>\n",
    "It throws the following error:<br>\n",
    "<h3>Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:46314)</h3>\n",
    "\n",
    "\n",
    "Therefore, I gradually increased the threshold from 0.0004 and noticed that FP-Growth is able to train the models at threashold = 0.0006. So for the rest of the question (and better results), I have used the min-support as 0.0006.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2176\n"
     ]
    }
   ],
   "source": [
    "support = 0.0006\n",
    "model = FPGrowth.train(venues, minSupport=support, numPartitions=1)\n",
    "result = model.freqItemsets().collect()\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import operator\n",
    "\n",
    "# prints a list of top 10 frequent venues for given seed conference\n",
    "def getTopVenues(result, name):\n",
    "    coVenues = {}\n",
    "    for fi in result:\n",
    "        if name in fi.items:\n",
    "            for venue in fi.items:\n",
    "                if venue!=name:\n",
    "                    coVenues[venue] = fi.freq if coVenues.get(venue) is None else coVenues.get(venue)+fi.freq\n",
    "#     print(coVenues)        \n",
    "    sortedVenues = sorted(sorted(coVenues.items(), key=operator.itemgetter(0)), key=operator.itemgetter(1), reverse=True)\n",
    "    top10 = itertools.islice(sortedVenues, 10)\n",
    "    for item in list(top10): \n",
    "        print(item[0])  \n",
    "    \n",
    "# for some seed conferences like VLDB, we also have \"VLDB Surveys\" do wee need to consider them\n",
    "# also \"VLDB J.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoRR\n",
      "ICML\n",
      "Neural Computation\n"
     ]
    }
   ],
   "source": [
    "name = \"NIPS\"\n",
    "getTopVenues(result, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoRR\n",
      "ICDM\n"
     ]
    }
   ],
   "source": [
    "name = \"KDD\"\n",
    "getTopVenues(result, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICDE\n",
      "SIGMOD Conference\n",
      "CoRR\n",
      "IEEE Trans. Knowl. Data Eng.\n"
     ]
    }
   ],
   "source": [
    "name = \"VLDB\"\n",
    "getTopVenues(result, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBECOM\n",
      "ICC\n",
      "IEEE Journal on Selected Areas in Communications\n",
      "IEEE/ACM Trans. Netw.\n",
      "CoRR\n",
      "Computer Networks\n",
      "Computer Communications\n",
      "ICDCS\n",
      "WCNC\n",
      "IEEE Trans. Parallel Distrib. Syst.\n"
     ]
    }
   ],
   "source": [
    "name = \"INFOCOM\"\n",
    "getTopVenues(result, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLING\n",
      "CoRR\n",
      "LREC\n"
     ]
    }
   ],
   "source": [
    "name = \"ACL\"\n",
    "getTopVenues(result, name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
